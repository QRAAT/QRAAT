#!/usr/bin/python
import matplotlib.pyplot as pp
import MySQLdb as mdb
import numpy as np
import time, os, sys
import qraat

# TODO parameters
cal_id=1
start_time_str = "201310140800"
stop_time_str =  "201310141200"
start_time = time.mktime(time.strptime(start_time_str,'%Y%m%d%H%M%S'))
stop_time = time.mktime(time.strptime(stop_time_str,'%Y%m%d%H%M%S'))
#start_time = 1376420800.0 # Cal run
#stop_time =  1376442000.0
# Get database credentials. 
try: 
  db_config = qraat.csv("%s/db_auth" % os.environ['RMG_SERVER_DIR']).get(view='reader')

except KeyError: 
  print >>sys.stderr, "position: error: undefined environment variables. Try `source rmg_env.`" 
  sys.exit(1) 

except IOError, e: 
  print >>sys.stderr, "position: error: missing DB credential file '%s'." % e.filename
  sys.exit(1)

# Connect to the database. 
db_con = mdb.connect(db_config.host, 
                     db_config.user,
                     db_config.password,
                     db_config.name)
cur = db_con.cursor()

print "position_est: fetching site and cal data"

# get site locations
sites = qraat.csv(db_con=db_con, db_table='sitelist')

# get steering vector data
# sv : site.ID -> (sv, bearing)
steering_vectors = {} # site.ID -> sv
bearings = {}         # site.ID -> bearing

for site in sites:
  cur.execute('''SELECT Bearing, 
                        sv1r, sv1i, sv2r, sv2i, 
                        sv3r, sv3i, sv4r, sv4i 
                   FROM Steering_Vectors 
                  WHERE SiteID=%d and Cal_InfoID=%d''' % (site.ID, cal_id))
  sv_data = np.array(cur.fetchall(),dtype=float)
  if sv_data.shape[0] > 0:
    steering_vectors[site.ID] = np.array(sv_data[:,1::2] + np.complex(0,1) * sv_data[:,2::2])
    bearings[site.ID] = np.array(sv_data[:,0])

print "position: fetching pulses for transmitter and time range"

#get pulses
cur.execute('''SELECT ID, siteid, timestamp,
                      ed1r, ed1i, ed2r, ed2i,
                      ed3r, ed3i, ed4r, ed4i
                 FROM est
                WHERE timestamp >= %s 
                  AND timestamp <= %s
                  AND txid = 55
                ORDER BY timestamp ASC''', (start_time, stop_time))
signal_data = np.array(cur.fetchall(), dtype=float)

est_ct = signal_data.shape[0]
if est_ct == 0:
  print >>sys.stderr, "position: fatal: no est records for selected time range."
  sys.exit(1)
else: print "position: processing %d records" % est_ct

sig_id =   np.array(signal_data[:,0], dtype=int)
site_id =  np.array(signal_data[:,1], dtype=int)
est_time = signal_data[:,2]
signal =   signal_data[:,3::2]+np.complex(0,-1)*signal_data[:,4::2]

# Calculate bearing likelihood per est record
likelihoods = np.zeros((est_ct,360))
for i in range(est_ct):
  # TODO error: no steering vectors for site_id
  sv =  steering_vectors[site_id[i]]
  sig = signal[i,np.newaxis,:]
  left_half = np.dot(sig, np.conj(np.transpose(sv)))
  bearing_likelihood = (left_half * np.conj(left_half)).real
  for j, value in enumerate(bearings[site_id[i]]):
    likelihoods[i, value] = bearing_likelihood[0, j]


def candidate_points(center, scale, half_span=15):
  ''' Generate candidate points for position estimation. 

    .. TODO: More intelligent bounds on grid size? 
  '''
  for east_index in range(-half_span, half_span+1): 
    for north_index in range(-half_span, half_span+1): 
      yield center + np.complex(north_index * scale, east_index * scale)

def position_estimation(i, j, center, scale):
  ''' Estimate the position of a transmitter over time interval ``[i, j]``. 

    (i, j) - interval over EST data 
    center - Center point for generating a grid of candidate points
    returns estimated point
  '''
  ll_max = 0.0
  point_max = center
  for pos in candidate_points(center, scale):
    ll_sum = 0.0
    bearings = {}
    for k in range(i, j):  
      # Bearing from receiver site to candidate point.
      # Memioizing prevents recalculation. 
      bearing = bearings.get(site_id[k])
      if not bearing:
        site = sites.get(ID=site_id[k])
        site_pos = np.complex(site.northing, site.easting)
        bearing = np.angle(pos - site_pos) * 180 / np.pi
        bearings[site_id[k]] = bearing

      # Look up the likelihood of the bearing. 
      # "Given the est signal and its source tower, 
      #  what is the likelihood of bearing from n+(j)e 
      #  to the tower?" 
      ll_sum += likelihoods[k, int(bearing + 0.5)]
     
    # See if averaged likelihood has improved our guess. 
    # NOTE by making an assumption about the rate at 
    # which the target moves, we can avoid choosing a 
    # bad candidate. 
    if ll_sum > ll_max:
      pos_max = pos
      ll_max = ll_sum

  return pos_max

#: Calculated positions (time, pos). 
pos_est = [] 

#: The time step (in seconds) for the position estimation
#: calculation.
t_delta = 1.0

#: Time averaging window (in seconds). 
t_window = 30.0

#: Center of Quail Ridge reserve (northing, easting). This is the first
#: "candidate point" used to construct the search space grid. 
center = np.complex(4260500, 574500) 

i = 0

try: 
  while i < est_ct - 1:

    # Find the index j corresponding to the end of the time window. 
    j = i + 1
    while j < est_ct - 1 and (est_time[j + 1] - est_time[i]) <= t_window: 
      j += 1
    
    print (i,j), (est_time[j] - est_time[i]), j - i
    
    scale = 100
    pos = center
    while scale >= 1: # 100, 10, 1 meters ...  
      pos = position_estimation(i, j, pos, scale)
      scale /= 10
    pos_est.append((est_time[(i + j) / 2], pos))

    # Step index i forward t_delta seconds. 
    j = i + 1
    while i < est_ct - 1 and (est_time[i + 1] - est_time[j]) <= t_delta: 
      i += 1

except KeyboardInterrupt: pass

finally:
  # Plot sites.
  pp.plot(
   [s.easting for s in sites], 
   [s.northing for s in sites], 'ro')

  # Plot locations. 
  pp.plot( 
   map(lambda (t,x): x.imag, pos_est), 
   map(lambda (t,x): x.real, pos_est), '.', alpha=0.3)

  pp.show()
