#!/usr/bin/python2
# rmg_filter
# Script to filter records both by parametric properties and time-based ones.
#
# Copyright (C) 2013-2014 Regents of the University of California
# Authored: Sean Riddle
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

# Testing with: txid=52 --siteid 2 or 3

import bisect
from collections import defaultdict
import cProfile
import csv
import datetime
import decimal
import itertools
import math
import numpy
import pickle
import re
import signal
import sys
import time

import qraat

# Minimum legitimate value before an exception is raised
CONFIG_MIN_INTERVAL = 0.8

# Minimum interval percentage difference which must occur from old value to
# trigger superceding of the interval with the new ones and re-scoring of
# slice.
CONFIG_INTERVAL_PERCENT_DIFFERENCE_THRESHOLD = 0.25

# How long a period the interval should be calculated over
CONFIG_INTERVAL_WINDOW_SIZE = float(3 * 60) # Three minutes (given in seconds)

# Search this many interval distances in both directions of a point for corroborating neighbors
CONFIG_DELTA_AWAY = 3

# Distance to look for neighbors while scoring
CONFIG_ERROR_ALLOWANCE = 0.2

# False if actually apply changes to database, True if just write script to file (update.sql in cwd)
CONFIG_JUST_STAGE_CHANGES = False

# Number of seconds to give as leeway before we assume that we can score
# everything exactly X minutes 
CONFIG_ARRIVAL_FUZZING = 10

# Defines the amount of time in seconds (fractional is fine, it is passed to time.sleep()) to wait between polling for new points.
CONFIG_NEW_STUFF_POLLING_PERIOD = 5

AWAKE = True
EXIT_REQUESTED = False

CURSOR_ENABLED = False

def noneFactory():
	return None

def parse_arguments(argv):
	args = defaultdict(noneFactory)
	while len(argv) != 0:
		value = argv.pop()
		field_name = argv.pop()
		prefix = '--'
		assert field_name.startswith(prefix)
		field_name = field_name[len(prefix):]
		args[field_name] = value
	return args

def pass_all(x):
	return True

def exit(signal, frame):
	global EXIT_REQUESTED
	if AWAKE:
		print 'Can\'t right now, sleeping.'
		EXIT_REQUESTED = True
	else:
		actually_exit()

def actually_exit():
	print 'Exiting'
	sys.exit(0)

def score(ids):
	db_con = qraat.util.get_db('writer')
	pass

def main():

	arguments = parse_arguments(sys.argv[1:])

	arg_t_start, arg_t_end = None, None

	past_score = True
	if 't_start' not in arguments or 't_end' not in arguments:
		print 'Please provide arguments t_start and t_end to specify appropriate ' + \
				'time range to process (e.g., --t_start 345 --t_end 700) to compute ' + \
				'static scores. The program will periodically poll and score new ' + \
				'incoming data.'
		past_score = False


		#sys.exit(1)
	else:
		arg_t_start = float(arguments['t_start'])
		arg_t_end = float(arguments['t_end'])

	if 'txid' not in arguments:
		print 'Please provide argument txid for transmitter ID to process'
		sys.exit(1)

	if 'siteid' not in arguments:
		print 'Please provide argument siteid for site ID to process'
		sys.exit(1)

	arg_txid = int(arguments['txid'])
	arg_siteid = int(arguments['siteid'])



	site_data = {}
	db_con = qraat.util.get_db('writer')

	if past_score:
		# score_the_past_chunking(arguments, arg_t_start, arg_t_end, arg_txid, arg_siteid)
		context_length = 3 * 60

		chunk_size = int(60 * 60)		# One hour (in seconds)
		total_chunks = int((arg_t_end - arg_t_start) / float(chunk_size)) + 1
		start_times = [(arg_t_start + (i * chunk_size)) for i in range(total_chunks)]
		intervals = [(x, min(arg_t_end, x + chunk_size)) for x in start_times]
		change_handler = init_change_handler()
		for start, end in intervals:
			# print '{} - {}'.format(start, end)
			# Get all unscored IDs in this chunk
			q = 'select t.ID from estscore RIGHT JOIN (select ID from est where siteid = %s and txid = %s and timestamp >= %s and timestamp <= %s) as t ON t.ID = estscore.estid where estscore.estid IS NULL;'
			#q = 'select est.ID from (select ID from est where siteid = %s and txid = %s and timestamp >= %s and timestamp <= %s left join estscore on est.ID = estscore.estid) where est where estscore.estid is null;'
			cur = db_con.cursor()
			rows = cur.execute(q, (arg_siteid, arg_txid, start, end))
			l = []
			while True:
				r = cur.fetchone()
				if r is None: break
				r = tuple(r)
				l.append(r[0])
			print 'Got {} items: {}'.format(len(l), l[:10])

			if len(l) == 0:
				print 'Nothing in this chunk...skipping...'
				continue

			process(db_con, change_handler, l)
			
			# Score all data between start and end using all data from start-3m to end+3m
			# score_the_past(arguments, start, end, txid, siteid)
	else:
		signal.signal(signal.SIGINT, exit)
		db_con = qraat.util.get_db('writer')
		change_handler = init_change_handler()
		while True:

			# Find all points that are not scored that are more than
			# about 3 minutes old (to give time to provide a
			# neighborhood for the scoring and to allow points to
			# arrive for the rate limiting filter to be effective.

			# There will be a partition of these points on whether or
			# not they are in an interval computed chunk (out-of-order)
			# vs. not in an interval computed chunk (in-order)

			
			
			current_timestamp = int(time.time())

			# Only look up to 5 minutes *before* the present
			limit = current_timestamp - (60 * 5)
			
			# Make sure we only examine complete windows.
			limit = limit - (limit % CONFIG_INTERVAL_WINDOW_SIZE)

			# NOTE: To prevent gigantic joins, there is an option to
			# limit the amount of time the "untimed" mode of operation
			# will look back. For now, 30 minutes.

			# base = current_timestamp - (60 * 30)
			base = None

			ids = get_unscored_est_ids_up_to(db_con, arg_siteid, arg_txid, limit, base=base)

			if len(ids) == 0:
				print 'There are no IDs currently unscored, back to sleep.'
				polling_delay()
				continue

			print 'Got the following unscored IDs:', ids

			data = read_est_records(db_con, ids)

			out_of_order_ids, in_order_ids, id_to_interval = partition_by_interval_calculation(db_con, ids, arg_siteid, arg_txid)

			print 'Found {} out of order, {} in order'.format(len(out_of_order_ids), len(in_order_ids))

			# param filter
			passed_filter_ids = parametrically_filter(db_con, data)

			print '{} items passed parametric filter'.format(len(passed_filter_ids))

			# Insert scores for parametrically bad points...
			for k in data.keys():
				if k in passed_filter_ids: continue
				change_handler.add_score(k, -2, 0)

			interval_chunked = time_chunk_ids(db_con, passed_filter_ids, data, CONFIG_INTERVAL_WINDOW_SIZE)

			interval_map = get_interval_map(out_of_order_ids, interval_chunked, id_to_interval)

			print '---------------------------------'
			for (k, v) in interval_map.items():
				print '{} -> {}'.format(k, v)
			print '---------------------------------'


			# Calculate brand new intervals for those which need it
			for k in interval_chunked:

				a = interval_chunked[k]
				b = get_parametric_passed_ids_in_chunk(db_con, k)
				# all_chunk_ids = interval_chunked[k] + get_parametric_passed_ids_in_chunk(db_con, k)
				all_chunk_ids = a + b

				if k not in interval_map:
					print 'No interval for {} yet.'.format(k)
					interval = calculate_interval(db_con, interval_chunked[k])
					if interval is None:
						print 'Problem with computing interval for this.'
					else:
						print 'Interval computed:', interval
						base, duration, siteid, txid = k
						store_interval_assume(change_handler, interval, base, duration, txid, siteid)
				else:
					# For each 'out-of-order' (already computed interval value)
					# chunk, re-compute the interval value and see if it
					# changes very much. If it does, recompute all time scores
					# in this chunk, if it does not, simply compute new scores
					# of unscored points in the chunk using the old interval
					# value.
					old_interval = interval_map[k]
					print 'Calculating out-of-order interval with {} items'.format(len(b))
					new_interval = calculate_interval(db_con, b)

					# Is new interval appreciably different from old interval?
					average = (old_interval + new_interval) / 2.
					percentage_difference = math.abs(new_interval - old_interval) / average
					if percentage_difference > CONFIG_INTERVAL_PERCENT_DIFFERENCE_THRESHOLD:
						pass

			
			scores = time_filter(db_con, passed_filter_ids)

			insert_scores(change_handler, scores)

			print 'Scores inserted.'


			
			

			



			polling_delay()
		# Add unscored points to a queue for scoring


def get_parametric_passed_ids_in_chunk(db_con, k):
	cur = db_con.cursor()
	base, duration, siteid, txid = k
	q = 'select t.ID from (select ID from est where timestamp >= %s and timestamp <= %s and siteid = %s and txid = %s) t LEFT JOIN estscore ON t.ID = estscore.estid AND absscore < 0;'
	cur.execute(q, (base, base + duration, siteid, txid))

	ids = []

	while True:
		r = cur.fetchone()
		if r is None: break
		r = tuple(r)
		ids.append(r[0])

	return ids


# Returns interval_map, which has keys from interval_chunked mapping to the
# interval that is given by id_to_interval for ids in value of interval_chunked
# (should all be the same; this is checked through assertions).

def get_interval_map(eligible_ids, interval_chunked, id_to_interval):

	intervals = defaultdict(list)

	for (k, ids) in interval_chunked.items():

		# Assert in or out
		is_eligible = [x in eligible_ids for x in ids]

		all_eligible = all(is_eligible)
		none_eligible = not any(is_eligible)
		if all_eligible:
			pass
		elif none_eligible:
			print 'None of these are eligible right now, no interval found.'
			continue
		else:
			print 'WARNING: Mixed up situation, some in, some out...problematic. Not processing these IDs.'
			continue
		
		interval = None
		try:
			interval = _get_interval_map_entry(ids, id_to_interval)
			assert interval is not None
			intervals[k].extend(ids)
		except NotAllSameValueError:
			print 'Uh oh! Not all the same!'

	return intervals

class NotAllSameValueError(Exception):
	def __init__(self):
		pass

def _get_interval_map_entry(ids, id_to_interval):
	for id in ids:
		assert id in id_to_interval
	vals = [id_to_interval[x] if x in id_to_interval else None for x in ids]
	if not all([x == vals[0] for x in vals]):
		raise NotAllSameValueError()
	return vals[0]

def partition_by_interval_calculation(db_con, ids, siteid, txid):
	print 'partition_by_interval_calculation()'

	cur = db_con.cursor()

	ids_template = ', '.join(map(lambda x : '{}', ids))
	id_string = ids_template.format(*ids)

	query_template = 'select t.ID as ID, interval_cache.period as period from (select ID, timestamp from est where ID in ({})) t LEFT JOIN interval_cache ON (t.timestamp >= interval_cache.start and t.timestamp <= interval_cache.start + interval_cache.valid_duration and interval_cache.txid = %s and interval_cache.siteid = %s)'
	query = query_template.format(id_string)

	print 'txid={}, siteid={}'.format(txid, siteid)
	print 'Query about to be run: "{}"'.format(query)

	cur.execute(query, (txid, siteid))

	out_of_order_ids, in_order_ids = [], []

	id_to_interval = {}

	while True:
		r = cur.fetchone()
		if r is None: break
		r = tuple(r)
		id, period = r
		print 'Raw:', r
		print 'Period:', period
		if period is None:
			in_order_ids.append(id)
		else:
			out_of_order_ids.append(id)
			id_to_interval[id] = period

	print 'partition_by_interval_calculation() end'
	return out_of_order_ids, in_order_ids, id_to_interval


PROCESS_GOOD = 0
PROCESS_BAD = 0

def process(db_con, change_handler, ids):

	global PROCESS_GOOD, PROCESS_BAD

	print 'Proceeding to process {} items.'.format(len(ids))

	# Processing list of new items.
	data = read_est_records(db_con, ids)


	# param filter
	passed_filter_ids = parametrically_filter(db_con, data)

	print '{} items passed parametric filter'.format(len(passed_filter_ids))

	# Insert scores for parametrically bad points...
	for k in data.keys():
		if k in passed_filter_ids: continue
		change_handler.add_score(k, -2, 0)

	interval_chunk = time_chunk_ids(db_con, passed_filter_ids, data, CONFIG_INTERVAL_WINDOW_SIZE)

	verify_chunking(passed_filter_ids, interval_chunk)

	print 'Calculating intervals for {} chunks'.format(len(interval_chunk))

	print 'There are {} intervals stored in DB right now'.format(get_db_interval_count(db_con))

	# Calculate intervals from these points
	for ((base, duration, siteid, txid), chunk_ids) in interval_chunk.items():
		print 'Processing chunk of {} items'.format(len(chunk_ids))
		# Could have calculate_intervals use the data as retrieved, but lets just keep the interface very simple for now.
		# chunk_ids = [x['ID'] for x in chunk_data]
		interval = calculate_interval(db_con, chunk_ids)
		if interval is not None:
			store_interval_assume(change_handler, interval, base, duration, txid, siteid)
			#def store_interval_assume(change_handler, interval, base, duration, txid, siteid):
			PROCESS_GOOD += 1
			print 'Actually storing interval!'
		else:
			print 'Interval could not be calculated'
			PROCESS_BAD += 1
	print 'Summary: good={}, bad={}'.format(PROCESS_GOOD, PROCESS_BAD)
		
	# time filter
	scores = time_filter(db_con, passed_filter_ids)

	print 'Remaining points scored'

	insert_scores(change_handler, scores)

	print 'Scores inserted.'

def get_db_interval_count(db_con):
	cur = db_con.cursor()
	rows = cur.execute('select count(*) from interval_cache;')
	r = cur.fetchone()
	r = tuple(r)
	return r[0]
	

def verify_chunking(all_ids, chunked_ids):
	set1 = set()
	set2 = set()
	set1.update(all_ids)
	for v in chunked_ids.values():
		set2.update(v)
	print '|1|: {}, |2|: {}, |1-2|: {}, |2-1|: {}, |1v2|: {}, |1^2|: {}'.format(len(set1), len(set2), len(set1.difference(set2)), len(set2.difference(set1)), len(set1.union(set2)), len(set1.intersection(set2)))
	

def insert_scores(change_handler, scores):
	for (id, score) in scores.items():
		rel_score_to_scale = score if score > 0 else 0
		change_handler.add_score(id, score, float(rel_score_to_scale) / (CONFIG_DELTA_AWAY * 2))
		#sql_w.write('update est set score = {} where ID = {};\n'.format(score, id))

def store_interval_assume(change_handler, interval, base, duration, txid, siteid):
	print 'Storing interval={}, {}+{}'.format(interval, base, duration)
	q = 'insert into interval_cache (period, start, valid_duration, txid, siteid) values (%s, %s, %s, %s, %s);'
	change_handler.add_sql(q, (interval, base, duration, txid, siteid))

def get_intervals_from_db(db_con, ids):

	print 'get intervals for:', ids

	cur = db_con.cursor()

	ids_template = ', '.join(map(lambda x : '{}', ids))
	id_string = ids_template.format(*ids)
	q = 'select t.ID, interval_cache.period from interval_cache RIGHT JOIN (select ID, timestamp, siteid, txid from est where ID in ({})) as t ON (t.siteid = interval_cache.siteid and t.txid = interval_cache.txid and t.timestamp >= interval_cache.start and t.timestamp <= interval_cache.start + interval_cache.valid_duration) where interval_cache.start IS NOT NULL;'

	row = cur.execute(q.format(id_string))

	intervals = {}

	while True:
		r = cur.fetchone()
		if r is None: break
		r = tuple(r)
		intervals[r[0]] = float(r[1])

	print 'Intervals returned from DB:', intervals

	return intervals
	
COUNT_GOOD = 0
COUNT_ALL = 0

def time_filter(db_con, ids):

	global COUNT_GOOD, COUNT_ALL

	if len(ids) == 0: return {}

	data = read_est_records(db_con, ids)

	all_timestamps = sorted([x['timestamp'] for x in data.values()])

	scores = defaultdict(int)

	intervals = get_intervals_from_db(db_con, ids)

	COUNT_ALL += 1

	if len(intervals) == 0:
		COUNT_GOOD += 1

	print 'Would write out data'
	# for d in data.values():
	# 	print '{} - {}'.format(d['ID'], d['timestamp'])

	print 'Intervals computed for DB:', len(intervals)

	# sys.exit(-1)

	for id in ids:

		score = None
		
		if id not in intervals:
			score = -1
			print 'No interval found for:', id
			assert False
		else:
			score = 0
			# sys.exit(-1)
			# calculate possible center points to investigate
			interval = intervals[id]
			tstamp = data[id]['timestamp']
			factors = [x for x in range(-CONFIG_DELTA_AWAY, CONFIG_DELTA_AWAY + 1) if x != 0]
			offsets = [x * interval for x in factors]
			absolute = [tstamp + x for x in offsets]
			search_space = [(x - CONFIG_ERROR_ALLOWANCE, x + CONFIG_ERROR_ALLOWANCE) for x in absolute]

			for start, end in search_space:
				start_ind = bisect.bisect_left(all_timestamps, start)
				end_ind = bisect.bisect_right(all_timestamps, end)
				if start_ind == end_ind:
					# No points found
					pass
				else:
					score += 1
			scores[id] = score

	print 'Currently {}/{}'.format(COUNT_GOOD, COUNT_ALL)

	return scores


def time_chunk_ids(db_con, ids, all_data, duration):

	if len(ids) == 0: return {}

	sorted_pairs = get_sorted_timestamps(db_con, ids)
	chunks = defaultdict(list)
	for (timestamp, id) in sorted_pairs:
		datum = all_data[id]
		# k = (basetime, duration)
		d, m = divmod(timestamp, duration)
		base = d * duration
		k = (base, duration, datum['siteid'], datum['txid'])
		# chunks[k].append(datum)
		chunks[k].append(id)

	return chunks

	


# Returns a list of IDs which pass the filter
def parametrically_filter(db_con, data):

	registry = qraat.signal_filter.Registry(None)
	for point in data.values():
		registry.register_point(point)

	# ids = registry.get_all_ids()

	scored_points = None

	good_stuff, bad_stuff, good_ids, bad_ids, good_points, bad_points, good_xs, bad_xs, = None, None, None, None, None, None, None, None

	good_stuff, bad_stuff = registry.screen_bad(registry.points)
	print 'Got {} good items and {} bad items'.format(len(good_stuff), len(bad_stuff))

	good_ids = [x['ID'] for x in good_stuff]
	bad_ids = [x['ID'] for x in bad_stuff]

	return good_ids


	




def init_change_handler():
	change_handler = None
	if CONFIG_JUST_STAGE_CHANGES:
		sql_output_filename = 'update.sql'
		sql_w = open(sql_output_filename, 'w')
		change_handler = qraat.signal_filter.ChangeHandler(sql_w, 'file')
	else:
		# NOTE: I don't declare the db connection here, because passing it
		# between modules seems to mess things up.
		change_handler = qraat.signal_filter.ChangeHandler(None, 'db')
	return change_handler


def get_unscored_est_ids_up_to(db_con, siteid, txid, limit, base=None):

	query = None
	cur = db_con.cursor()

	if base is None:
		query = 'select t.ID from (select est.ID from est where timestamp <= %s and txid = %s and siteid = %s) t left join estscore on t.ID = estscore.estid where estscore.absscore IS NULL'
		cur.execute(query, (limit, txid, siteid))
	else:
		print 'base:', base
		print 'limit:', limit
		query = 'select t.ID from (select est.ID from est where timestamp >= %s and timestamp <= %s and txid = %s and siteid = %s) t left join estscore on t.ID = estscore.estid where estscore.absscore IS NULL'
		cur.execute(query, (base, limit, txid, siteid))

	ids = []
	while True:
		r = cur.fetchone()
		if r is None: break
		r = tuple(r)
		ids.append(r[0])

	return ids


def read_est_records(db_con, ids):

	if len(ids) == 0:
		return []

	cur = db_con.cursor()

	fields = ('ID', 'band3', 'band10', 'timestamp', 'siteid', 'txid')

	ids_template = ', '.join(map(lambda x : '{}', ids))
	id_string = ids_template.format(*ids)
	field_string = ', '.join(fields)
	print 'Going to read {} ids'.format(len(ids))

	q = 'SELECT {} FROM est WHERE ID IN ({});'.format(field_string, id_string)
	rows = cur.execute(q)
	
	site_data = {}
	r = None
	while True:
		r = cur.fetchone()
		if r is None: break
		r = tuple(r)
		named_row = dict(zip(fields, r))
		for k in named_row:
			if named_row[k].__class__ == decimal.Decimal:
				named_row[k] = float(named_row[k])
		site_data[named_row['ID']] = named_row

	return site_data






	# if CURSOR_ENABLED:
	# 	all_ts = [x['timestamp'] for x in registry.points]
	# 	max_just_processed = max(all_ts)
    #
	# 	sql = 'select * from `cursor` where name = %s and value > %s;'
	# 	rows = change_handler.add_sql(sql, ('estscore', max_just_processed))
	# 	if rows > 0:
	# 		# noop
	# 		print 'No need to update cursor'
	# 	else:
	# 		sql = 'delete from `cursor` where name = %s;'
	# 		change_handler.add_sql(sql, ('estscore',))
	# 		sql = 'insert into `cursor` (name, value) values (%s, %s);'
	# 		change_handler.add_sql(sql, ('estscore', max_just_processed))




def score_new_things(ids, db_con, change_handler):

	fields = ('ID', 'band3', 'band10', 'timestamp', 'siteid', 'txid')

	rows = None

	cur = None

	# if CURSOR_ENABLED:
	# 	cur = db_con.cursor()
	# 	q = 'select value from `cursor` where name = %s;'
	# 	rows_back = cur.execute(q, ('estscore',))
	# 	assert rows_back == 1
	# 	r = cur.fetchone()
	# 	r = tuple(r)
	# 	assert len(r) == 1
	# 	max_val = r[0]
	# 	print 'Got max val: {} ({})'.format(r, r.__class__)
	# 	# raw_input()
	# 	cur = db_con.cursor()
	# 	q = 'select ID from est where timestamp > %s;'
	# 	rows = cur.execute(q, (max_val,))
	if False:
		pass
	else:

		cur = db_con.cursor()

		# Get all timestamp data for non-time scored things yet
		#timestamp_data = get_fields_for(db_con, ids, 'timestamp')

		latest_timestamp = get_latest_timestamp(db_con)
		print 'Got latest timestamp:', latest_timestamp
		id_data = get_time_filter_eligible_unscored(db_con, latest_timestamp)

		# Find all points whose interval could be changed by this
		get_interval_range(id_data)
		# id_data contains the data about points that are at old enough that there are some records observed outside of the scoring window. So the point can be scored.
		interval_data = get_intervals_for(db_con, id_data)

		print 'Reporting...'
		for id, interval in interval_data.items():
			print 'For ID {} - interval = {}'.format(id, interval)



	# intervals = {}
    #
	# for id, v in id_data.items():
	# 	# cur = db_con.cursor()
	# 	timestamp = v['timestamp']
	# 	siteid = v['siteid']
	# 	txid = v['txid']
	# 	interval = add_record_for_interval(db_con, timestamp, siteid, txid)
	# 		
	# 	intervals[id] = interval
	# 	
	# return intervals





def get_interval_range(id_data):
	print 'get_interval_range({})'.format(id_data.__class__)


def polling_delay():
	global AWAKE
	AWAKE = False
	print 'Zzz...'
	if EXIT_REQUESTED:
		print 'Processing earlier exit request.'
		actually_exit()
	time.sleep(CONFIG_NEW_STUFF_POLLING_PERIOD)
	AWAKE = True
	print 'Wha!'
	

	
def get_latest_timestamp(db_con):

	cur = db_con.cursor()

	query = 'select max(timestamp) from est;'
	rows = cur.execute(query)
	assert rows == 1

	row = cur.fetchone()
	val = row[0]

	return float(val)

def get_time_filter_eligible_unscored(db_con, latest_timestamp):
	nothing_newer_than = latest_timestamp - CONFIG_INTERVAL_WINDOW_SIZE - CONFIG_ARRIVAL_FUZZING
	cur = db_con.cursor()
	query = 'select est.ID, est.timestamp, est.siteid, est.txid from est left join estscore on est.id = estscore.estid where estscore.absscore < 0 and timestamp <= %s'
	rows = cur.execute(query, (nothing_newer_than,))
	print 'Trying to get filter eligible unprocessed, got {} rows'.format(rows)

	ids = {}

	while True:
		row = cur.fetchone()
		if row is None:
			break
		else:
			row = tuple(row)
			d = {'ID':int(row[0]), 'timestamp':float(row[1]), 'siteid':int(row[2]), 'txid':int(row[3])}
			ids[d['ID']] = d
			# ids.append((row[0], row[1]))

	print 'Got {} values'.format(len(ids))
	return ids

def add_record_for_interval(db_con, timestamp, siteid, txid, recalculate=False):
	cur = db_con.cursor()
	q = 'select ID, period from interval_cache where start <= %s and (start + valid_duration) >= %s and siteid = %s and txid = %s;'
	rows = cur.execute(q, (timestamp, timestamp, siteid, txid))
	assert rows <= 1

	interval = None

	if rows == 0:
		print 'Calculating and storing interval!'
		# Calculate interval and store in database
		d, m = divmod(timestamp, CONFIG_INTERVAL_WINDOW_SIZE)
		start = d * CONFIG_INTERVAL_WINDOW_SIZE # Could also be timestamp - m
		valid_duration = CONFIG_INTERVAL_WINDOW_SIZE
		interval = calculate_interval(db_con, start, start + valid_duration, siteid, txid)
		q = 'insert into interval_cache (txid, siteid, start, valid_duration, period) values (%s, %s, %s, %s, %s);'
		cur = db_con.cursor()
		cur.execute(q, (txid, siteid, start, valid_duration, interval))
		print 'Performed insertion!'
	else:
		if recalculate:
			# Calculate interval and store in database
			r = cur.fetchone()
			r = tuple(r)
			id = r[0]
			update_statement = 'update interval_cache set txid = %s, siteid = %s, start = %s, valid_duration = %s, period %s;'
			d, m = divmod(timestamp, CONFIG_INTERVAL_WINDOW_SIZE)
			start = d * CONFIG_INTERVAL_WINDOW_SIZE # Could also be timestamp - m
			valid_duration = CONFIG_INTERVAL_WINDOW_SIZE
			interval = calculate_interval(db_con, start, start + valid_duration, siteid, txid)
			cur = db_con.cursor()
			cur.execute(update_statement, (txid, siteid, start, valid_duration, period))
			#q = 'insert into interval_cache (txid, siteid, start, valid_duration, period) values (%s, %s, %s, %s, %s);'
			#cur = db_con.cursor()
			#cur.execute(q, (txid, siteid, start, valid_duration, interval))
			#print 'Performed insertion!'
		else:
			r = cur.fetchone()
			r = tuple(r)
			interval = r[0]

	return interval



	# intervals = {}
    #
	# for id, v in id_data.items():
	# 	# cur = db_con.cursor()
	# 	timestamp = v['timestamp']
	# 	siteid = v['siteid']
	# 	txid = v['txid']
	# 	interval = add_record_for_interval(db_con, timestamp, siteid, txid)
	# 		
	# 	intervals[id] = interval
	# 	
	# return intervals
	

def calculate_interval(db_con, ids):

	print 'calculate_interval for {} values'.format(len(ids))

	sorted_pairs = get_sorted_timestamps(db_con, ids)
	print 'Got {} sorted pairs'.format(len(sorted_pairs))
	print '---'
	for (i, (timestamp, val)) in enumerate(sorted_pairs):
		print '{}. {}'.format(i + 1, timestamp)
	print '---'

	interval_windows = qraat.signal_filter.WindowIterator(sorted_pairs, None)

	intervals = []

	# There should only be one.
	for (i, w) in enumerate(interval_windows):
		print 'Processed interval window:', (i+1)
		interval = w.calculate_interval_from()
		print 'Produced interval:', interval
		intervals.append(interval)
	assert len(intervals) == 1
	return intervals[0]

def get_sorted_timestamps(db_con, ids):
	cur = db_con.cursor()

	ids_template = ', '.join(map(lambda x : '{}', ids))
	id_string = ids_template.format(*ids)
	query = 'SELECT ID, timestamp FROM est where ID IN ({});'.format(id_string)
	print 'About to execute query "{}"'.format(query)
	rows = cur.execute(query)

	# rows = cur.execute(q, (start, start + end, siteid, txid))
	print 'Calculating interval from {} values...'.format(rows)

	# Have to format the data as a sequence of (timestamp, id) 2-tuples...

	pairs = []

	while True:
		r = cur.fetchone()
		if r is None:
			break
		else:
			r = tuple(r)
			id = int(r[0])
			timestamp = float(r[1])
			t = (timestamp, id)
			pairs.append(t)

	sorted_pairs = sorted(pairs)

	return sorted_pairs
	

def different_main():
	db_con = qraat.util.get_db('writer')

	siteid = 2
	txid = 59

	in_ids = (214188049, 214188050, 214188051, 214188052, 214188053, 214188054)
	out_ids = (214200952,)

	all_ids = in_ids + out_ids

	out_order, in_order = partition_by_interval_calculation(db_con, all_ids, siteid, txid)

	print '{} out of order, {} in order'.format(len(out_order), len(in_order))


if __name__ == '__main__':
	# different_main()
	main()

