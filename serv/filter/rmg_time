#!/usr/bin/python2
# rmg_filter
# Script to filter records both by parametric properties and time-based ones.
#
# Copyright (C) 2013-2014 Regents of the University of California
# Authored: Sean Riddle
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

# Testing with: txid=52 --siteid 2 or 3

import bisect
from collections import defaultdict
import cProfile
import csv
import datetime
import decimal
import itertools
import math
import numpy
import pickle
import re
import signal
import sys
import time

import qraat

# Minimum legitimate value before an exception is raised
CONFIG_MIN_INTERVAL = 0.8

# How long a period the interval should be calculated over
CONFIG_INTERVAL_WINDOW_SIZE = float(3 * 60) # Three minutes (given in seconds)

# Search this many interval distances in both directions of a point for corroborating neighbors
CONFIG_DELTA_AWAY = 3

# Distance to look for neighbors while scoring
CONFIG_ERROR_ALLOWANCE = 0.2

# False if actually apply changes to database, True if just write script to file (update.sql in cwd)
CONFIG_JUST_STAGE_CHANGES = False

# Number of seconds to give as leeway before we assume that we can score
# everything exactly X minutes 
CONFIG_ARRIVAL_FUZZING = 10

# Defines the amount of time in seconds (fractional is fine, it is passed to time.sleep()) to wait between polling for new points.
CONFIG_NEW_STUFF_POLLING_PERIOD = 5

AWAKE = True
EXIT_REQUESTED = False

CURSOR_ENABLED = True

def filter_site(s):
	sites = s.split(',')
	sites = [int(x.strip()) for x in sites]
	def f(x):
		return x['siteid'] in sites
	def g(x):
		return x in sites
	return f, g

def filter_txid(s):
	txids = s.split(',')
	txids = [int(x.strip()) for x in txids]
	def f(x):
		return x['txid'] in txids
	def g(x):
		return x in txids
	return f, g

def noneFactory():
	return None

def parse_arguments(argv):
	args = defaultdict(noneFactory)
	while len(argv) != 0:
		value = argv.pop()
		field_name = argv.pop()
		prefix = '--'
		assert field_name.startswith(prefix)
		field_name = field_name[len(prefix):]
		args[field_name] = value
	return args

def pass_all(x):
	return True

def exit(signal, frame):
	global EXIT_REQUESTED
	if AWAKE:
		print 'Can\'t right now, sleeping.'
		EXIT_REQUESTED = True
	else:
		actually_exit()

def actually_exit():
	print 'Exiting'
	sys.exit(0)

def main():

	arguments = parse_arguments(sys.argv[1:])

	arg_t_start, arg_t_end = None, None

	past_score = True
	if 't_start' not in arguments or 't_end' not in arguments:
		print 'Please provide arguments t_start and t_end to specify appropriate ' + \
				'time range to process (e.g., --t_start 345 --t_end 700) to compute ' + \
				'static scores. The program will periodically poll and score new ' + \
				'incoming data.'
		past_score = False


		#sys.exit(1)
	else:
		arg_t_start = float(arguments['t_start'])
		arg_t_end = float(arguments['t_end'])

	if 'txid' not in arguments:
		print 'Please provide argument txid for transmitter ID to process'
		sys.exit(1)

	if 'siteid' not in arguments:
		print 'Please provide argument siteid for site ID to process'
		sys.exit(1)

	arg_txid = int(arguments['txid'])
	arg_siteid = int(arguments['siteid'])



	site_data = {}

	if past_score:
		score_the_past_chunking(arguments, arg_t_start, arg_t_end, arg_txid, arg_siteid)
	else:
		signal.signal(signal.SIGINT, exit)
		db_con = qraat.util.get_db('writer')
		change_handler = init_change_handler()
		while True:
			# Everything that has not been scored at all (even new stuff will be parametrically filtered)
			print 'frontier_parametric_score()'
			ids = frontier_parametric_score(db_con, arg_txid, arg_siteid, change_handler, arguments)

			# If there are intervals that have not been calculated yet - indicated by 
			# print 'maybe_measure_new_interval()'
			# maybe_measure_new_interval(ids, db_con, arg_txid, arg_siteid, change_handler)

			# print 'Shutting down agreeably...'
			# sys.exit(1)

			print 'score_new_things()'
			score_new_things(ids, db_con, change_handler)

			polling_delay()
		# Add unscored points to a queue for scoring

def init_change_handler():
	change_handler = None
	if CONFIG_JUST_STAGE_CHANGES:
		sql_output_filename = 'update.sql'
		sql_w = open(sql_output_filename, 'w')
		change_handler = qraat.signal_filter.ChangeHandler(sql_w, 'file')
	else:
		# NOTE: I don't declare the db connection here, because passing it
		# between modules seems to mess things up.
		change_handler = qraat.signal_filter.ChangeHandler(None, 'db')
	return change_handler

def score_the_past_chunking(arguments, t_start, t_end, txid, siteid):

	context_length = 3 * 60			# Three minutes of context is assumed in the chunk (thus the middle 54 minutes of data will actually be scored
	#t_start = t_start - context_length
	#t_end = t_end + context_length

	chunk_size = int(60 * 60)		# One hour (in seconds)
	total_chunks = int((t_end - t_start) / float(chunk_size)) + 1
	start_times = [(t_start + (i * chunk_size)) for i in range(total_chunks)]
	intervals = [(x, x + chunk_size) for x in start_times]
	for start, end in intervals:
		# Score all data between start and end using all data from start-3m to end+3m
		score_the_past(arguments, start, end, txid, siteid)

def score_the_past(arguments, t_start, t_end, txid, siteid):

	db_con = qraat.util.get_db('writer')

	# Something ...
	cur = db_con.cursor()

	fields = ('ID', 'band3', 'band10', 'timestamp', 'siteid', 'txid')

	rows = cur.execute('SELECT {} FROM est where timestamp >= {} and timestamp <= {} and txid = {} and siteid = {};'.format(', '.join(fields), t_start, t_end, txid, siteid)) # Oink oink
	
	print 'Rows processed:', rows
	site_data = {}
	row = -1
	while True:
		row = cur.fetchone()
		if row is None:
			break
		else:
			row = tuple(row)
		named_row = dict(zip(fields, row))
		for k in named_row:
			if named_row[k].__class__ == decimal.Decimal:
				named_row[k] = float(named_row[k])
		site_data[named_row['ID']] = named_row

	change_handler = init_change_handler()



	# Just a test
	db_con.close()





	# Bucket site_data by (siteid, txid).
	#bucketed = {}
	buckets = defaultdict(list)
	if len(site_data) == 0:
		print 'No data in this chunk'
		return

	assert len(site_data) > 0
	for v in site_data.values():
		k = (v['siteid'], v['txid'])
		#print 'iterating through:', k
		buckets[k].append(v)

	assert len(buckets) == 1

	filter_txid_f, filter_txid_simple_f = pass_all, pass_all
	if arguments['filter-txid'] is not None:
		filter_txid_f, filter_txid_simple_f = filter_txid(arguments['filter-txid'])

	filter_site_f, filter_site_simple_f = pass_all, pass_all
	if arguments['filter-site'] is not None:
		filter_site_f, filter_site_simple_f = filter_site(arguments['filter-site'])

	all_sites = set()
	all_sites.update([x[0] for x in buckets.keys()])
	all_txids = set()
	all_txids.update([x[1] for x in buckets.keys()])
	print 'all sites ({}): {}'.format(len(all_sites), all_sites)
	print 'all txids ({}): {}'.format(len(all_txids), all_txids)

		
	#if just_stage_changes:
	#change_handler = qraat.signal_filter.ChangeHandler(

	# Setting up connection to database...


	# Only processing one

	for i, site_and_txid in enumerate(buckets.keys()):
		site_id, txid = site_and_txid
		if not filter_site_simple_f(site_id):
			#print 'Filtering bucket by site'
			continue

		if not filter_txid_simple_f(txid):
			#print 'Filtering bucket by txid'
			continue

		registry = qraat.signal_filter.Registry(arguments)
		for point in buckets[site_and_txid]:
			registry.register_point(point)

		#values = registry.get_all_ids()

		#ids = [x[0] for x in values]

		ids = registry.get_all_ids()

		scored_points = None

		#use_time_filter = arguments['time-filter'] is not None
		#hide_bad_points = arguments['hide-bad'] is not None
		# Eliminate unnecessary conditional when this all works, for now:
		use_time_filter, hide_bad_points = True, False

		good_stuff, bad_stuff, good_ids, bad_ids, good_points, bad_points, good_xs, bad_xs, = None, None, None, None, None, None, None, None

		print 'Partitioning {} points'.format(len(buckets[site_and_txid]))
		if use_time_filter or hide_bad_points:
			good_stuff, bad_stuff = registry.screen_bad(registry.points)
			print 'Got {} good items and {} bad items'.format(len(good_stuff), len(bad_stuff))

			good_ids = [x['ID'] for x in good_stuff]
			bad_ids = [x['ID'] for x in bad_stuff]
			# TODO: Danger
			#good_points = [(x['timestamp'], x[item_to_plot]) for x in good_stuff]
			#bad_points = [(x['timestamp'], x[item_to_plot]) for x in bad_stuff]
			#good_xs, good_ys = zip(*good_points)
			#bad_xs, bad_ys = zip(*bad_points)
			good_xs = [x['timestamp'] for x in good_stuff]
			bad_xs = [x['timestamp'] for x in bad_stuff]
			for bad_id in bad_ids:
				change_handler.add_score(bad_id, -2, 0)
				#sql_w.write('update est set score = -1 where ID = {};\n'.format(bad_id))

		if use_time_filter:
			points_under_consideration = []
			print 'Attempting temporal alignment'
			print 'Got {} good points'.format(len(good_ids))
			# Create list of intervals.
			#intervals = []
			for i in range(len(good_xs)):
				x = good_xs[i]
				id = good_ids[i]
				points_under_consideration.append((x, id))

			# Generate ALL points struct
			all_points_data = list(points_under_consideration)
			for i in range(len(bad_xs)):
				x = bad_xs[i]
				id = bad_ids[i]
				all_points_data.append((x, id))

			score_unclean_data = False

			if score_unclean_data:
				scored_points_dirty = apply_time_filtering(all_points_data, txid, interval_computation_only_data=points_under_consideration)
				scored_points_clean = apply_time_filtering(points_under_consideration, txid)
				assert scored_points_dirty.keys() == scored_points_clean.keys()
				def bad_score(x):
					return x < 2
				agree = 0
				for (pid, dirty_score) in scored_points_dirty.items():
					clean_score = scored_points_clean[pid]
					if not (bad_score(clean_score) ^ bad_score(dirty_score)):
						agree += 1
				disagree = len(scored_points_dirty) - agree
				print 'Comparing dirty points scored with interval timing with leaving them out: {} agree, {} disagree'.format(agree, disagree)
			else:
				scored_points = apply_time_filtering(points_under_consideration, txid)

			for (id, score) in scored_points.items():
				change_handler.add_score(id, score, float(score) / (CONFIG_DELTA_AWAY * 2))
				#sql_w.write('update est set score = {} where ID = {};\n'.format(score, id))

	if CURSOR_ENABLED:
		all_ts = [x['timestamp'] for x in registry.points]
		max_just_processed = max(all_ts)

		sql = 'select * from `cursor` where name = %s and value > %s;'
		rows = change_handler.add_sql(sql, ('estscore', max_just_processed))
		if rows > 0:
			# noop
			print 'No need to update cursor'
		else:
			sql = 'delete from `cursor` where name = %s;'
			change_handler.add_sql(sql, ('estscore',))
			sql = 'insert into `cursor` (name, value) values (%s, %s);'
			change_handler.add_sql(sql, ('estscore', max_just_processed))



def apply_time_filtering(points_under_consideration, txid, interval_computation_only_data=None):
	print 'begin apply_time_filtering()'

	arguments = parse_arguments(sys.argv[1:])

	sorted_points = sorted(points_under_consideration)

	#((min_x, min_y, min_id), (max_x, max_y, max_id)) = sorted_points[0], sorted_points[-1]

	interval_window_size = CONFIG_INTERVAL_WINDOW_SIZE

	interval_windows = None
	if interval_computation_only_data is None:
		interval_windows = qraat.signal_filter.WindowIterator(sorted_points, interval_window_size)
	else:
		interval_windows = qraat.signal_filter.WindowIterator(interval_computation_only_data, interval_window_size)

	print 'Window count: {}'.format(interval_windows.get_window_count())

	total_data = 0



	# Here's what to do...

	for (i, w) in enumerate(interval_windows):
		interval = w.calculate_interval_from(txid=txid, slice_id=i+1)
		w.attach_property('interval', interval)
		print 'attached attribute "interval"'

	interval_windows.report()

	# Interval values are calculated.
	# Go over these windows with a sub-window, a scoring window centered around
	# each point. Must be able to access the interval of a point falling within
	# a particular interval qraat.signal_filter.

	#interval = interval_windows.get_property_for_point(point, 'interval')



	scores = {}

	all_timestamps = [x[0] for x in sorted_points]

	for (tstamp, ident) in sorted_points:
		# Scoring this point (with id=ident)
		score = 0
		# get appropriate interval
		interval = interval_windows.get_property_for_point(tstamp, 'interval')
		if interval < CONFIG_MIN_INTERVAL:
			# Skipping for now
			#raise Exception('Found interval abnormally low: {}'.format(interval))
			print 'Found interval abnormally low: {}'.format(interval)
			scores[ident] = 0
			continue

		# calculate possible center points to investigate
		factors = [x for x in range(-CONFIG_DELTA_AWAY, CONFIG_DELTA_AWAY + 1) if x != 0]
		offsets = [x * interval for x in factors]
		absolute = [tstamp + x for x in offsets]
		search_space = [(x - CONFIG_ERROR_ALLOWANCE, x + CONFIG_ERROR_ALLOWANCE) for x in absolute]

		for start, end in search_space:
			start_ind = bisect.bisect_left(all_timestamps, start)
			end_ind = bisect.bisect_right(all_timestamps, end)
			if start_ind == end_ind:
				# No points found
				pass
			else:
				score += 1
		scores[ident] = score

	print 'Calculated scores for {} points'.format(len(scores))
	unscored_because_low = [x for (x, y) in scores.items() if y == 2]
	print '{} points were not totally processed because an interval could not be calculated (the calculated value is not reasonable)'.format(len(unscored_because_low))
	return scores



	#interval_windows = qraat.signal_filter.WindowIterator(sorted_points, interval_window_size)

	for (i, w) in enumerate(interval_windows):
		v = w.value()
		print 'There are {} points in window {}:'.format(len(v), (i+1))
		print 'There are {} attributes'.format(len(w.attributes))
		total_data += len(v)
		for (k, v) in w.attributes.items():
			print '\t{} -> {}'.format(k, v)

	assert total_data == len(sorted_points)



def get_bucket_for(x, bounds):
	gap = bounds[1] - bounds[0]
	curr_min, curr_max = None, None
	for (b_ind, boundary) in enumerate(bounds):
		if boundary > x:
			curr_min = bounds[b_ind - 1]
			curr_max = boundary
			break
	if curr_min is None and curr_max is None:
		curr_min = bounds[-1]
		curr_max = curr_min + gap
	return curr_min, curr_max

def get_center_points(x, min, max, interval):
	points = []
	if x is None: print 'x is none'
	if interval is None: print 'interval is none'
	i = x - interval
	# Look down...
	while i > min:
		points.append(i)
		i -= interval

	i = x + interval
	while i < max:
		points.append(i)
		i += interval

	return points

def interpolate_interval(interval_map, ident):
	keys = interval_map.keys()
	print 'interpolate_interval()'.format(ident, ', '.join([str(z) for z in keys]))
	max_not_above = None
	min_not_below = None
	for k in keys:
		if (max_not_above is None or k > max_not_above) and k < ident:
			max_not_above = k
		if (min_not_below is None or k < min_not_below) and k > ident:
			min_not_below = k

	if max_not_above is None and min_not_below is None:
		print '!!!!!!!!!!!!\n!!!!!!!!!!!!\n!!!!!!!!!!!!\n!!!!!!!!!!!!\n'
		raise Exception()

	if max_not_above is None:
		return interval_map[min_not_below]
	if min_not_below is None:
		return interval_map[max_not_above]

	low_val = interval_map[max_not_above]
	high_val = interval_map[min_not_below]

	# get line defined by (max_not_above, low_val) and (min_not_below, high_val)

	#(x1, y1)
	#(x2, y2)

	#slope = (y2 - y1) / (x2 - x1)
	#y = mx + b
	#y = ((y2 - y1) / (x2 - x1)) x + b

	#y1 = ((y2 - y1) / (x2 - x1)) x1 + b
	#b = y1 - ((y2 - y1) / (x2 - x1)) * x1

	slope = (high_val - low_val) / float(min_not_below - max_not_above)
	b = low_val - ((high_val - low_val) / float(min_not_below - max_not_above)) * max_not_above

	# Sanity check
	l = slope * max_not_above + b
	h = slope * min_not_below + b
	#print 'Started with {}, ended up with {}'.format(low_val, l)
	#print 'Started with {}, ended up with {}'.format(high_val, h)

	return slope * ident + b

# point is a time float
# points is a list of all point floats for the hour, in order

SEARCH_START, SEARCH_END = None, None

def reset_points_radius_search():
	global SEARCH_START, SEARCH_END
	SEARCH_START = None
	SEARCH_END = None

def are_points_in_radius(point, points, radius):
	print 'are_points_in_radius()'
	global SEARCH_START, SEARCH_END

	low, high = point - radius, point + radius
	print 'low thresh:', low
	print 'high thresh:', high

	if SEARCH_START is None and SEARCH_END is None:
		print 'initializing vals'
		# initialize the search points using bisect calls
		SEARCH_START = bisect.bisect_left(points, low)
		SEARCH_END = bisect.bisect_left(points, high)
		pass
	else:
		assert SEARCH_START is not None and SEARCH_END is not None
		# maintain SEARCH_START and SEARCH_END

		###
		# |---&------|---&
		###
		#print 'maintaining'

		#print 'SEARCH_START={}, SEARCH_END={}, |points|={}'.format(SEARCH_START, SEARCH_END, len(points))

		while points[SEARCH_START] <= low:
			SEARCH_START += 1
		SEARCH_START -= 1

		while SEARCH_END < len(points) and points[SEARCH_END] <= high:
			SEARCH_END += 1

		#if SEARCH_END > 0:
			#SEARCH_END -= 1
		#else:
			#print 'Asserted!'
			#assert SEARCH_END == 0
			#if SEARCH_START != 0:
				#print 'This would have sent the SEARCH_END ({}) negative...{}'.format(SEARCH_END, SEARCH_START)
			#assert SEARCH_START == 0

	# both of SEARCH_START and SEARCH_END are set

	print 'Searching a slice of size:', (SEARCH_END - SEARCH_START)

	if (SEARCH_END - SEARCH_START) < 0:
		print 'SEARCH_START={}, SEARCH_END={}, |points|={}'.format(SEARCH_START, SEARCH_END, len(points))

	for i in range(SEARCH_START, SEARCH_END):
		_point = points[i]
		if _point == point:
			print 'Skipping self point'
			continue

		if _point >= low and _point <= high:
			print 'Yes, there\'s something in here'
			return True
	print 'There is nothing there'
	return False

# def maybe_measure_new_interval(ids, db_con, txid, siteid, change_handler):
# 	# Score last completed one if it isn't already scored.
# 	CONFIG_INTERVAL_WINDOW_SIZE
# 	pass

def frontier_parametric_score(db_con, txid, siteid, change_handler, arguments):

	fields = ('ID', 'band3', 'band10', 'timestamp', 'siteid', 'txid')

	rows = None

	cur = None

	# if CURSOR_ENABLED:
	# 	cur = db_con.cursor()
	# 	q = 'select value from `cursor` where name = %s;'
	# 	rows_back = cur.execute(q, ('paramscore',))
	# 	assert rows_back == 1 or rows_back == 0
	# 	r = cur.fetchone()
	# 	r = tuple(r)
	# 	assert len(r) == 1
	# 	max_val = r[0]
	# 	print 'Got max val: {} ({})'.format(r, r.__class__)
	# 	# raw_input()
	# 	cur = db_con.cursor()
	# 	q = 'select ID from est where timestamp > %s;'
	# 	rows = cur.execute(q, (max_val,))
	# else:

	cur = db_con.cursor()


	# NOTE: Set a timestamp here to only score unscored points whose timestamp is newer than this.
	time_starts_at = None
	# get all unscored points
	q = None
	if time_starts_at is None:
		q = 'select est.ID from est LEFT JOIN estscore ON est.ID = estscore.estid where estscore.estid IS NULL and txid = {} and siteid = {};'.format(txid, siteid)
	else:
		q = 'select est.ID from est LEFT JOIN estscore ON est.ID = estscore.estid where estscore.estid IS NULL and timestamp >= {} and txid = {} and siteid = {};'.format(time_starts_at, txid, siteid)
	rows = cur.execute(q)



	if rows == 0:
		print 'Nothing new yet.'
	else:
		print 'There are {} new rows'.format(rows)
	pass

	if rows == 0:
		print 'Nothing new...'
		return
	else:

		ids = []

		while True:
			r = cur.fetchone()
			if r is None:
				break
			else:
				r = tuple(r)
				assert len(r) == 1
				ids.append(r[0])



		ids_template = ', '.join(map(lambda x : '{}', ids))
		id_string = ids_template.format(*ids)
		field_string = ', '.join(fields)
		query = 'SELECT {} FROM est where ID in ({});'.format(field_string, id_string)
		print 'About to execute query "{}"'.format(query)
		rows = cur.execute(query)
		print 'Got {} records returned.'.format(rows)


		all_rows = []

		while True:
			r = cur.fetchone()
			if r is None:
				 break
			else:
				named_row = dict(zip(fields, r))
				named_row['timestamp'] = float(named_row['timestamp'])
				all_rows.append(named_row)
		print 'Parsed {} rows'.format(len(all_rows))

		registry = qraat.signal_filter.Registry(arguments)
		for point in all_rows:
			print 'Registering point:', point
			registry.register_point(point)






		
		good_stuff, bad_stuff = registry.screen_bad(registry.points)
		for good_item in good_stuff:
			change_handler.add_score(good_item['ID'], -1, 0)
			print 'Setting score to -1'
		for bad_item in bad_stuff:
			change_handler.add_score(bad_item['ID'], -2, 0)
			print 'Setting score to -2'

		return ids
		

def score_new_things(ids, db_con, change_handler):

	fields = ('ID', 'band3', 'band10', 'timestamp', 'siteid', 'txid')

	rows = None

	cur = None

	# if CURSOR_ENABLED:
	# 	cur = db_con.cursor()
	# 	q = 'select value from `cursor` where name = %s;'
	# 	rows_back = cur.execute(q, ('estscore',))
	# 	assert rows_back == 1
	# 	r = cur.fetchone()
	# 	r = tuple(r)
	# 	assert len(r) == 1
	# 	max_val = r[0]
	# 	print 'Got max val: {} ({})'.format(r, r.__class__)
	# 	# raw_input()
	# 	cur = db_con.cursor()
	# 	q = 'select ID from est where timestamp > %s;'
	# 	rows = cur.execute(q, (max_val,))
	if False:
		pass
	else:

		cur = db_con.cursor()

		# Get all timestamp data for non-time scored things yet
		#timestamp_data = get_fields_for(db_con, ids, 'timestamp')

		latest_timestamp = get_latest_timestamp(db_con)
		print 'Got latest timestamp:', latest_timestamp
		id_data = get_time_filter_eligible_unscored(db_con, latest_timestamp)
		interval_data = get_intervals_for(db_con, id_data)

		print 'Reporting...'
		for id, interval in interval_data.items():
			print 'For ID {} - interval = {}'.format(id, interval)

def get_fields_for(db_con, ids, fields):

	# NOTE: Set a timestamp here to only score unscored points whose timestamp is newer than this.
	time_starts_at = None
	# get all unscored points
	q = None
	if time_starts_at is None:
		q = 'select est.ID from est LEFT JOIN estscore ON est.ID = estscore.estid where estscore.estid IS NULL and txid = {} and siteid = {};'.format(txid, siteid)
	else:
		q = 'select est.ID from est LEFT JOIN estscore ON est.ID = estscore.estid where estscore.estid IS NULL and timestamp >= {} and txid = {} and siteid = {};'.format(time_starts_at, txid, siteid)
	rows = cur.execute(q)

	if rows == 0:
		print 'Nothing new yet.'
	else:
		print 'There are {} new rows'.format(rows)

	ids = []
	while True:
		row = cur.fetchone()
		if row is None:
			break
		else:
			row = tuple(row)
			assert len(row) == 1
			ids.append(row[0])
	print 'New IDs:', ids

	if len(ids) == 0:
		print 'No new points found yet.'
		# polling_delay()
		print 'ddcc:', dir(cur)
		return
	
	ids_template = ', '.join(map(lambda x : '{}', ids))
	id_string = ids_template.format(*ids)
	field_string = ', '.join(fields)
	query = 'SELECT {} FROM est where ID in ({});'.format(field_string, id_string)
	print 'About to execute query "{}"'.format(query)
	rows = cur.execute(query)
	print 'Got {} records returned.'.format(rows)

	print 'Preparing to score {} EST records...'.format(rows)

	new_rows = []

	for row in cur.fetchall():
		
		named_row = dict(zip(fields, row))
		print 'Processing row:', named_row
		new_rows.append(named_row)


	# Re-calculate intervals for windows that have new data	
	invalidated_windows = set()
	for row in new_rows:
		window_starts = int(float(row['timestamp']) / CONFIG_INTERVAL_WINDOW_SIZE)
		invalidated_windows.add(window_starts)

	print '{} new points trigger the recomputation of {} interval windows'.format(len(new_rows), len(invalidated_windows))

	# A batch of things arrives, some of which may be late arriving
	out_of_order = []
	# It gets populated somehow.
	
	# Sort of half mark those things because we are doing the intervals with them in mind
	for new_id in ids:
		print 'Adding score'
		change_handler.add_score(new_id, 0, 0)

	# for point in out_of_order:
	# 	w = qraat.signal_filter.get_window_for_point(point, offset=-1)




	# Configurable delay between subsequent calls happens here.
	# polling_delay()
		
			
	
	
	# Find invalidated intervals: what is in batch within a computed interval
	# For each invalidated interval, recompute and update
	# Add all points affected by an invalidated interval to the queue for scoring
	# Score each point in the queue for scoring

	#cur.execute('SELECT {} FROM est where txid = {} and siteid = {};'.format(', '.join(fields), arg_txid, arg_siteid))

def polling_delay():
	global AWAKE
	AWAKE = False
	print 'Zzz...'
	if EXIT_REQUESTED:
		print 'Processing earlier exit request.'
		actually_exit()
	time.sleep(CONFIG_NEW_STUFF_POLLING_PERIOD)
	AWAKE = True
	print 'Wha!'
	

def get_fields_for(db_con, ids, fields):

	cur = db_con.cursor()

	ids_template = ', '.join(map(lambda x : '{}', ids))
	id_string = ids_template.format(*ids)
	field_string = ', '.join(fields)
	query = 'SELECT {} FROM est where ID in ({});'.format(field_string, id_string)
	print 'About to execute query "{}"'.format(query)
	rows = cur.execute(query)
	
	all_rows = []
	for row in rows:
		row = tuple(row)
		named_row = dict(zip(fields, row))
		all_rows.append(named_rows)
	
	keyed_by_id = {}
	for row in all_rows:
		keyed_by_id[row['ID']] = row

	return keyed_by_id
	
def get_latest_timestamp(db_con):

	cur = db_con.cursor()

	query = 'select max(timestamp) from est;'
	rows = cur.execute(query)
	assert rows == 1

	row = cur.fetchone()
	val = row[0]

	return float(val)

def get_time_filter_eligible_unscored(db_con, latest_timestamp):
	nothing_newer_than = latest_timestamp - CONFIG_INTERVAL_WINDOW_SIZE - CONFIG_ARRIVAL_FUZZING
	cur = db_con.cursor()
	query = 'select est.ID, est.timestamp, est.siteid, est.txid from est left join estscore on est.id = estscore.estid where estscore.absscore < 0 and timestamp <= %s'
	rows = cur.execute(query, (nothing_newer_than,))
	print 'Trying to get filter eligible unprocessed, got {} rows'.format(rows)

	ids = {}

	while True:
		row = cur.fetchone()
		if row is None:
			break
		else:
			row = tuple(row)
			d = {'ID':int(row[0]), 'timestamp':float(row[1]), 'siteid':int(row[2]), 'txid':int(row[3])}
			ids[d['ID']] = d
			# ids.append((row[0], row[1]))

	print 'Got {} values'.format(len(ids))
	return ids

def get_intervals_for(db_con, id_data):

	intervals = {}

	for id, v in id_data.items():
		cur = db_con.cursor()
		timestamp = v['timestamp']
		siteid = v['siteid']
		txid = v['txid']
		q = 'select period from interval_cache where start <= %s and (start + valid_duration) >= %s and siteid = %s and txid = %s;'
		rows = cur.execute(q, (timestamp, timestamp, siteid, txid))
		assert rows <= 1
		interval = None
		if rows == 0:
			d, m = divmod(timestamp, CONFIG_INTERVAL_WINDOW_SIZE)
			start = d * CONFIG_INTERVAL_WINDOW_SIZE # Could also be timestamp - m
			valid_duration = CONFIG_INTERVAL_WINDOW_SIZE
			interval = calculate_interval(db_con, start, start + valid_duration, siteid, txid)
			q = 'insert into interval_cache (txid, siteid, start, valid_duration, period) values (%s, %s, %s, %s, %s);'
			cur = db_con.cursor()
			cur.execute(q, (txid, siteid, start, valid_duration, interval))
			print 'Performed insertion!'
			# Calculate interval and store in database
		else:
			r = cur.fetchone()
			r = tuple(r)
			interval = r[0]
			
		intervals[id] = interval
		
	return intervals
	

def calculate_interval(db_con, start, end, siteid, txid):
	print 'Calculating one-off interval between {} and {} - {} seconds...'.format(start, end, (end - start))

	cur = db_con.cursor()

	# Get all data in this window that is not parametrically bad
	q = 'select est.ID, timestamp from est JOIN estscore ON est.ID = ' + \
		'estscore.estid where timestamp >= %s and timestamp <= %s and ' + \
		'absscore != -2 and siteid = %s and txid = %s;'
		# Note the use of the sentinel value for parametrically bad stuff in estscore.

	rows = cur.execute(q, (start, start + end, siteid, txid))
	print 'Calculating interval from {} values...'.format(rows)

	# Have to format the data as a sequence of (timestamp, id) 2-tuples...

	pairs = []

	while True:
		r = cur.fetchone()
		if r is None:
			break
		else:
			r = tuple(r)
			id = int(r[0])
			timestamp = float(r[1])
			t = (timestamp, id)
			pairs.append(t)

	sorted_pairs = sorted(pairs)
	
	interval_windows = qraat.signal_filter.WindowIterator(sorted_pairs, None)

	intervals = []

	# There should only be one.
	for (i, w) in enumerate(interval_windows):
		print 'Processed interval window:', (i+1)
		interval = w.calculate_interval_from()
		intervals.append(interval)
	assert len(intervals) == 1
	return intervals[0]




if __name__ == '__main__':
	#cProfile.run('main()')
	main()
	#succ = are_points_in_radius(1.3, (0.5, 1.7, 3.7), 0.2)
	#print 'Returned true' if succ else 'Returned false'

