**General Process for training and evolution of XXX method:**

1. Add required data table for the method to the database.
2. Run XXX_trainer.py to train the method.
3. Run classifier_evulation_XXX.py for classify the testing set.
4. Run evaluation_result to print the results in tabular form.


**Scripts:**

- *class_setNum* - Split the data in each combination of deployment and site into ten nearly equal sized blocks for 10-fold cross-validation usage. The algorithm counts the number of est’s in each of the 10 folds and randomly assign numbers from 0 to 9 to each of the est until the count runs out. It does this to both manual and likelihood labelings.
- *classifier_evaluation_bandwidthFilter* - Do 10-fold cross-validation on each combination of deployment and site. It uses the qualification of both band3 < 450 and band10 < 900 to classify whether an est is a pulse. It counts the number of TP, TN, FP, FN, and total records for each of the 10 validation sets and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *classifier_evulation_estScoreFilter* - Do 10-fold cross-validation on each combination of deployment and site. It uses the qualification of eat score <= 5 to classify whether an est is a pulse. It counts the number of TP, TN, FP, FN, and total records for each of the 10 validations sets and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *NBC_trainer* - It calculates the mean and variance of each variable for each combination of deployment and site. In addition, it calculates the proportion of each unique value of band3, band10, and frequency for the pulse data and scale it to normalize the mixed distribution with gaussian outside of these unique values. It does this to each of the 10-fold cross-validation training set. It also train on both manual and likelihood labelings. 
- *classifier_evulation_NBC* - Do 10-fold cross-validation on each combination of deployment and site. It calculates the likelihood of both noise and pulse with the assumption of all variables are normally distributed. It classifies the observation with the class of higher likelihood. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *classifier_evulation_modifiedBC* - It works the same as *classifier_evulation_NBC* except it take the discrete varibles into account and construct mixed distribution for band3, band10, and frequency.
- *decisionTree_trainer* - For each of 10-fold cross-validations it first keep 1/9 of the training data for pruning procedure and use the rest of 8/9 the training data to build the tree. At each branch, it calculates the entropy of each possible split if the number of the data is less than 100, else it calculates the entropy at each 100 intervals between minimun and maximum. It uses the split with the lowest weighted sum of entropy to branch and add the tree node to the current tree. For each of the left and right children, it check if the number of observations is < 5, all observations has the same class, or all observations has the same values for all variables. If so, it terminates the child and append a leaf node to the tree with the class of the highest occurrence. Else, it recursively calls the algorithm with the child. After the tree is built, it uses the withheld data to calculate the error rate of the tree. For each leaf node, it check if by modifying the parent node to one of the class will reduce the error rate of the tree. If it does, the leaf node is removed and the parent node is modified to a leaf node and will be checked again. It continues this process until all leaf nodes are checked to make sure the tree gets the best error rate for this withheld data. It does this algorithm for each conbination of 10-fold cross-validation, deployment, and site. It also does this to both manual and likelihood labelings.
- *classifier_evulation_decisionTree* - Do 10-fold cross-validation on each combination of deployment and site. It loads the decision tree learned from the training set and classify each observations in the validation set. It classifies the observation with the class of the leaf node traversed through the tree. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *randomForests_trainer* - For each of the 10-fold cross-validation, it build 9 complete trees with bootstrapped data. At each split, it only check the entropy of randomly sampled 3 variables and use the one with lowest entropy to branch the data. It built the tree without pruning. It does this to each combination of deployment and site. It also does this algorithm to both manual and likelihood labelings.
- *classifier_evulation_randomForests* - Do 10-fold cross-validation on each combination of deployment and site. It loads 9 decision trees learned from the bootstrapped training set and classify each observations in the validation set. It traverses the observation through each of the 9 trees and classifies it with the class of majority of trees classification. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *SVM_trainer* - It does a grid search on C and gamma using the held-out method of randomly withhold 2/8 of data to calculate the error rate. If the number of observations > 1000, it will bootstrap 1000 observation to fit the SVM. It uses sklearn’s SVC to fit the model for each combination of C and gamma as well as predicting the error of the model for the withheld data. It then uses the combination of C and gamma with the lowest error to train the model. Again, if the number of training observations > 1000 observations, it will bootstrap 1000 observations before fitting the model. It then export each alpha’s with the estID associated to *SVM_alpha* table, constant b in hyperplane to *SVM_b* table, and the gamma used to train the model to *SVM_gamma* table. It does this algorithm to each combination of 10-fold cross-validation, deployment, and site. It also does this to both manual and likelihood labelings.
- *classifier_evulation_SVM* - Do 10-fold cross-validation on each combination of deployment and site. It calculates the value of hyperplane with an observation. It classifies the observation to pulse if the value is positive and to noise if the value is negative. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *evaluation_results* - It loads the results from *classifier_performance* table and shows the result in a tabular form. It does this to both manual and likelihood labelings.


**Tables (add “2” after table name for likelihood labeling):**

- *est_bearing* – likelihood of the expected bearing. Use for labeling process.
- *est_class* – labeling and validation set number of each est data.
- *classifier_performance* – the count of TP, TN, FP, FN and total records for each combination of deployment, validation, and classifier type.
- *estscore2* – the est score of the data used in this project. The scores are determined by the z value of each variable. 
- *est_mean_and_var* – the mean and the variance of each class for each combination of site and deployment. Use to determine the probabilities in NBC and modified BC.
- *probability_of_discrete_data* – the mixed probability distributions for band3, band10, and frequency for each of unique value of pulse. Use to determine the probabilities in modified BC.
- *decision_tree* – the trees for each combination of deployment and site. Use to classify in decision tree method.
- *random_forests* – the forests for each combination of deployment and site. Use to classify in random_forests method.
- *SVM_gamma* - the gamma value used to train the final SVM. Use to classify in SVM.
- *SVM_b* - the constant in the hyperplane for SVM. Use to classify in SVM.
- *SVM_alpha* - the nonzero alpha values with the estID its associated with. Use to classify in SVM.
