**General Process for training and evolution of XXX method:**

1. Add required data table for the method to the database.
2. Run XXX_trainer.py to train the method.
3. Run classifier_evulation_XXX.py for classify the testing set.
4. Run evaluation_result to print the results in tabular form.


**Scripts:**

- *class_setNum* - Split the data in each deployment and site combinations into ten nearly equal sized blocks for 10-fold cross-validation usage. The algorithm counts the number of est’s in each of the 10 folds and randomly assign numbers from 0 to 9 to each of the est until the count runs out. It does this to both manual and likelihood labelings.
- *classifier_evaluation_bandwidthFilter* - Do 10-fold cross-validation on each deployment and site combination. It uses the qualification of both band3 < 450 and band10 < 900 to classify whether an est is a pulse. It counts the number of TP, TN, FP, FN, and total records for each of the 10 validations sets and export the results into classifier_performance table. It does this to both manual and likelihood labelings.
- *classifier_evulation_estScoreFilter* - Do 10-fold cross-validation on each deployment and site combination. It uses the qualification of eat score <= 5 to classify whether an est is a pulse. It counts the number of TP, TN, FP, FN, and total records for each of the 10 validations sets and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *NBC_trainer* - It calculates the mean and variance of each variable for each deployment and site combination. In addition, it calculates the proportion of each unique value of band3, band10, and frequency for the pulse data and scale it to normalize the mixed distribution with gaussian outside of these unique values. It does this to each of the 10-fold cross-validation training set to both manual and likelihood labelings. 
- *classifier_evulation_NBC* - Do 10-fold cross-validation on each deployment and site combination. It calculates the likelihood of both noise and pulse with the assumption of all variables are normally distributed. It classifies the observation with the class of higher likelihood. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *classifier_evulation_modifiedBC* - It works the same as *classifier_evulation_NBC* except it take the discrete values into account and construct mixed distribution for band3, band10, and frequency.
- *decisionTree_trainer* - For each of 10-fold cross-validations it first keep 1/9 of data for pruning procedure and use the rest of 8/9 data to build the tree. At each branch, it calculates the entropy of each possible split if the number of data is less than 100 or it calculate the entropy at each 100 interval between minimun and maximum. It uses the split with the lowest weighted sum of entropy to branch and add the tree node to the current tree. For each of the left and right children, it check if the number of observations is < 5, all observations has the same class, or all observations has the same values for all variables. If so, it terminate the child and append a leaf to the tree with the class of the highest occurrence. Else, it recursively calls the algorithm to the child. After the tree is built, it uses the withhold data to calculate the error rate with the tree. For each leaf, it check if by modifying the parent node to one of the class will  reduce the accuracy of the withheld data. If it does, the leaf is removed and the parent is modified to the leaf and will be checked again. It continues this process until all leaf is check to make sure the tree gets the best error rate for this withheld data. It does this algorithm for each of 10-fold cross-validations, deployment, and site combinations. It also does this to both manual and likelihood labelings.
- *classifier_evulation_decisionTree* - Do 10-fold cross-validation on each deployment and site combination. It loads the decision tree learned from the training set and classify each observations in the validation set. It classifies the observation with the class of the leaf node traversed through the tree. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *randomForests_trainer* - For each of the 10-fold cross-validation, it build 9 complete trees with bootstrapped data. At each split, it only check the entropy of randomly sampled 3 variables and use the one with lowest entropy to branch the data. It built the tree without pruning. It does this to each of deployment and site combination. It also does this algorithm to both manual and likelihood labelings.
- *classifier_evulation_randomForests* - Do 10-fold cross-validation on each deployment and site combination. It loads 9 decision trees learned from the bootstrapped training set and classify each observations in the validation set. It traverses the observation through each of the 9 trees and classifies it with the class of majority of trees classification. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *SVM_trainer* - It does a grid search on C and gamma using the held-out method with randomly withhold 2/8 of data to calculate the error rate. If the number of observations if greater than 1000, it will bootstrap 1000 observation to fit SVM. It uses sklearn’s svm to fit the model for each C and gamma combination as well as predicting the error of the model for the withheld data. It then uses the C and gamma combination with the lowest error to train the model. Again, if the entire training set is greater than 1000 observations, it will bootstrap 1000 observations before fitting the model. It then export each alpha’s with the estID associated to *SVM_alpha* table, constant b in hyperplane to *SVM_b* table, and the gamma used to train the model to *SVM_gamma* table. It does this algorithm to each of 10-fold cross-validation, deployment, and site combination. It also does this to both manual and likelihood labelings.
- *classifier_evulation_SVM* - Do 10-fold cross-validation on each deployment and site combination. It calculates the value of hyperplane with an observation. It classifies the observation to pulse if the value is positive and to noise if the value is negative. It counts the number of TP, TN, FP, FN, and total records for each of the 10-fold cross-validation set and export the results into *classifier_performance* table. It does this to both manual and likelihood labelings.
- *evaluation_results* - It loads the results from *classifier_performance* table and shows the result in a tabular form. It does this to both manual and likelihood labelings.


**Tables (add “2” after table name for likelihood labeling):**

- *est_bearing* – likelihood of the expected bearing. Use for labeling process.
- *est_class* – labeling and validation set number of each est data.
- *classifier_performance* – the count of TP, TN, FP, FN and total records for each deployment, validation, and classifier type combinations.
- *estscore2* – the est score of the data used in this project. The scores are determined by the z value of each variable. 
- *est_mean_and_var* – the mean and the variance of each class for each site and deployment combinations. Use to determine the probabilities in NBC and modified BC.
- *probability_of_discrete_data* – the mixed probability distributions for band3, band10, and frequency for each of unique value of pulse. Use to determine the probabilities in modified BC.
- *decision_tree* – the trees for each deployment and site combinations. Use to classify in decision tree method.
- *random_forests* – the forests for each deployment and site combinations. Use to classify in random_forests method.
- *SVM_gamma* - the gamma value used to train the final SVM. Use to classify in SVM.
- *SVM_b* - the constant in the hyperplane for SVM. Use to classify in SVM.
- *SVM_alpha* - the nonzero alpha values with the estID its associated with. Use to classify in SVM.
